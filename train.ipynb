{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting CoLA...\n",
      "\tCompleted!\n",
      "Downloading and extracting SST...\n",
      "\tCompleted!\n",
      "Processing MRPC...\n",
      "Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n",
      "\tCompleted!\n",
      "Downloading and extracting QQP...\n",
      "\tCompleted!\n",
      "Downloading and extracting STS...\n",
      "\tCompleted!\n",
      "Downloading and extracting MNLI...\n",
      "\tCompleted!\n",
      "Downloading and extracting SNLI...\n",
      "\tCompleted!\n",
      "Downloading and extracting QNLI...\n",
      "\tCompleted!\n",
      "Downloading and extracting RTE...\n",
      "\tCompleted!\n",
      "Downloading and extracting WNLI...\n",
      "\tCompleted!\n",
      "Downloading and extracting diagnostic...\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "%run -i download_glue.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/09/2019 10:44:47 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "07/09/2019 10:44:50 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-vocab.json from cache at C:\\Users\\v-qianl\\.pytorch_pretrained_bert\\4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6\n",
      "07/09/2019 10:44:50 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading merges file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-merges.txt from cache at C:\\Users\\v-qianl\\.pytorch_pretrained_bert\\0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76\n",
      "07/09/2019 10:44:50 - WARNING - pytorch_pretrained_bert.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "07/09/2019 10:44:50 - INFO - pytorch_pretrained_bert.tokenization_openai -   Special tokens {'_start_': 40478, '_delimiter_': 40479, '_classify_': 40480}\n",
      "07/09/2019 10:44:52 - INFO - pytorch_pretrained_bert.modeling_openai -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-pytorch_model.bin from cache at C:\\Users\\v-qianl\\.pytorch_pretrained_bert\\e45ee1afb14c5d77c946e66cb0fa70073a77882097a1a2cefd51fd24b172355e.e7ee3fcd07c695a4c9f31ca735502c090230d988de03202f7af9ebe1c3a4054c\n",
      "07/09/2019 10:44:52 - INFO - pytorch_pretrained_bert.modeling_openai -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-config.json from cache at C:\\Users\\v-qianl\\.pytorch_pretrained_bert\\a27bb7c70e9002d7558d2682d5a95f3c0a8b31034616309459e0b51ef07ade09.f59b19eb0e361a0230a1106b66b8c6e7a994cb200cd63d9190cda8d56d75ff85\n",
      "07/09/2019 10:44:52 - INFO - pytorch_pretrained_bert.modeling_openai -   Model config {\n",
      "  \"afn\": \"gelu\",\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 512,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 512,\n",
      "  \"n_special\": 0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"vocab_size\": 40478\n",
      "}\n",
      "\n",
      "07/09/2019 10:44:59 - INFO - __main__ -   ***** Running training *****\n",
      "07/09/2019 10:44:59 - INFO - __main__ -     Num examples = 8551\n",
      "07/09/2019 10:44:59 - INFO - __main__ -     Batch size = 32\n",
      "07/09/2019 10:44:59 - INFO - __main__ -     Num steps = 804\n",
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 268/268 [05:04<00:00,  1.01s/it]\n",
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 268/268 [05:19<00:00,  1.04s/it]\n",
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 268/268 [05:20<00:00,  1.00it/s]\n",
      "07/09/2019 11:00:46 - INFO - pytorch_pretrained_bert.modeling_openai -   loading weights file experiment/CoLA\\pytorch_model.bin\n",
      "07/09/2019 11:00:46 - INFO - pytorch_pretrained_bert.modeling_openai -   loading configuration file experiment/CoLA\\config.json\n",
      "07/09/2019 11:00:46 - INFO - pytorch_pretrained_bert.modeling_openai -   Model config {\n",
      "  \"afn\": \"gelu\",\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 512,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 512,\n",
      "  \"n_special\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"vocab_size\": 40478\n",
      "}\n",
      "\n",
      "07/09/2019 11:00:50 - INFO - run_classifier_dataset_utils -   Writing example 0 of 1043\n",
      "07/09/2019 11:00:50 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
      "07/09/2019 11:00:50 - INFO - run_classifier_dataset_utils -   guid: dev-0\n",
      "07/09/2019 11:00:50 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> sailors</w> rode</w> the</w> breeze</w> clear</w> of</w> the</w> rocks</w> .</w> _delimiter_\n",
      "07/09/2019 11:00:50 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 13092 5135 481 4728 1949 498 481 4720 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:50 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:50 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:50 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
      "07/09/2019 11:00:50 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   guid: dev-1\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> weights</w> made</w> the</w> rope</w> stretch</w> over</w> the</w> pul ley</w> .</w> _delimiter_\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 17422 885 481 4159 6253 715 481 967 1616 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   guid: dev-2\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> mechanical</w> doll</w> wriggled</w> itself</w> loose</w> .</w> _delimiter_\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 11617 7764 16777 2754 3644 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   *** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   guid: dev-3\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   tokens: _start_ if</w> you</w> had</w> eaten</w> more</w> ,</w> you</w> would</w> want</w> less</w> .</w> _delimiter_\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   input_ids: 40478 645 512 558 5783 725 240 512 636 823 1101 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   guid: dev-4\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   tokens: _start_ as</w> you</w> eat</w> the</w> most</w> ,</w> you</w> want</w> the</w> least</w> .</w> _delimiter_\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   input_ids: 40478 557 512 2425 481 905 240 512 823 481 1423 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/09/2019 11:00:51 - INFO - run_classifier_dataset_utils -   label: 0 (id = 0)\n",
      "07/09/2019 11:00:51 - INFO - __main__ -     Saving eval features into cached file glue_data/COLA\\dev_openai-gpt_128_cola\n",
      "07/09/2019 11:00:51 - INFO - __main__ -   ***** Running evaluation *****\n",
      "07/09/2019 11:00:51 - INFO - __main__ -     Num examples = 1043\n",
      "07/09/2019 11:00:51 - INFO - __main__ -     Batch size = 8\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 131/131 [00:17<00:00,  7.30it/s]\n",
      "07/09/2019 11:01:09 - INFO - __main__ -   ***** Eval results *****\n",
      "07/09/2019 11:01:09 - INFO - __main__ -     eval_loss = 0.4928024184555953\n",
      "07/09/2019 11:01:09 - INFO - __main__ -     global_step = 804\n",
      "07/09/2019 11:01:09 - INFO - __main__ -     loss = 0.09691035539949712\n",
      "07/09/2019 11:01:09 - INFO - __main__ -     mcc = 0.5033071972797099\n"
     ]
    }
   ],
   "source": [
    "%run -i run_classifier.py --task_name COLA --do_train --do_eval --data_dir glue_data/COLA --max_seq_length 128 --train_batch_size 32 --eval_batch_size 8 --learning_rate 2e-5 --num_train_epochs 3.0 --output_dir experiment/CoLA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
